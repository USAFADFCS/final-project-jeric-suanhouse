{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b925b2",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0afe050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EBliv\\Downloads\\Computer Science\\final-project-aymeric-et-louis\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = '1'\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from fairlib.utils.document_processor import DocumentProcessor\n",
    "\n",
    "from fairlib import (\n",
    "    settings,\n",
    "    AbstractTool,\n",
    "    ManagerPlanner,\n",
    "    HierarchicalAgentRunner,\n",
    "    Message,\n",
    "    HuggingFaceAdapter,\n",
    "    ToolRegistry,\n",
    "    ToolExecutor,\n",
    "    WorkingMemory,\n",
    "    LongTermMemory,\n",
    "    ChromaDBVectorStore,\n",
    "    ReActPlanner,\n",
    "    SimpleAgent,\n",
    "    SentenceTransformerEmbedder,\n",
    "    SimpleRetriever,\n",
    "    KnowledgeBaseQueryTool  # <-- Using the official framework tool\n",
    ")\n",
    "\n",
    "# ChromaDB for vector storage\n",
    "try:\n",
    "    import chromadb\n",
    "    CHROMADB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: chromadb not installed. Install with: pip install chromadb\")\n",
    "    CHROMADB_AVAILABLE = False\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "\n",
    "if not token:\n",
    "    print(\"Warning: HUGGING_FACE_HUB_TOKEN not found in .env file!\")\n",
    "else:\n",
    "    print(\"Token loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca0d1e6",
   "metadata": {},
   "source": [
    "## Loading LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0c4fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading language model...\n",
      "ðŸ”§ Loading HuggingFace model: cognitivecomputations/Dolphin3.0-Qwen2.5-3b (quantized=False, stream=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading language model...\")\n",
    "llm = HuggingFaceAdapter(\n",
    "    model_name=\"dolphin3-qwen25-3b\", \n",
    "    auth_token=token,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    "    max_new_tokens=512,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab19667a",
   "metadata": {},
   "source": [
    "## Importing Fair LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab0c553f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All components imported!\n"
     ]
    }
   ],
   "source": [
    "from fairlib import (\n",
    "    HuggingFaceAdapter,\n",
    "    ToolRegistry,\n",
    "    SafeCalculatorTool,\n",
    "    ToolExecutor,\n",
    "    WorkingMemory,\n",
    "    SimpleAgent, \n",
    "    SimpleReActPlanner,\n",
    "    RoleDefinition\n",
    ")\n",
    "\n",
    "print(\"All components imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b427bb",
   "metadata": {},
   "source": [
    "## Tool Creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dbb25dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Specialized tools created!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "# ---- Optional: keep your safe soundfile-based saver (avoids torchaudio I/O issues) ----\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "def _safe_save_audio(wav, path, samplerate, **kwargs):\n",
    "    wav_np = wav.detach().cpu().numpy()\n",
    "    if wav_np.ndim == 1:\n",
    "        wav_np = wav_np[np.newaxis, :]\n",
    "    sf.write(path, wav_np.T, samplerate)\n",
    "    print(f\"âœ… Saved safely: {path}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "class AbstractTool:\n",
    "    \"\"\"Minimal stand-in so this example is self-contained.\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    def use(self, tool_input: str) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SeparateStemsTool(AbstractTool):\n",
    "    \"\"\"Tool for separating music into stems using Demucs\"\"\"\n",
    "\n",
    "    name = \"separate_stems\"\n",
    "    description = (\n",
    "        \"Separates an audio file into stems (vocals, drums, bass, etc.) using Demucs.\\n\"\n",
    "        \"Input (JSON string): { 'input_file': 'path/to/audio.mp3', \"\n",
    "        \"'output_dir': 'separated_stems', 'model_name': 'htdemucs_6s' }.\\n\"\n",
    "        \"Returns: a formatted report with saved file paths.\"\n",
    "    )\n",
    "\n",
    "    def _separate_stems(self, input_file: str, output_dir: str = \"separated_stems\",\n",
    "                        model_name: str = \"htdemucs\") -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Core separation routine. Loads Demucs, runs separation, and saves stems.\n",
    "        Returns a dict of {stem_name: path}.\n",
    "        \"\"\"\n",
    "        # Lazy imports so importing the tool is cheap\n",
    "        import torch\n",
    "        import librosa\n",
    "        import numpy as np\n",
    "        from demucs.pretrained import get_model\n",
    "        from demucs.apply import apply_model\n",
    "        from demucs import audio as demucs_audio\n",
    "        import torchaudio\n",
    "\n",
    "        # Monkey-patch Demucs' save_audio to our safe soundfile-based version\n",
    "        demucs_audio.save_audio = _safe_save_audio\n",
    "\n",
    "        if not os.path.exists(input_file):\n",
    "            raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "\n",
    "        # Load audio (stereo @ 44.1k)\n",
    "        y, sr = librosa.load(input_file, sr=44100, mono=False)\n",
    "        if y.ndim == 1:\n",
    "            y = y[np.newaxis, :]  # (channels, samples)\n",
    "        wav = torch.from_numpy(y).float().unsqueeze(0)  # (1, C, T)\n",
    "\n",
    "        # Load model\n",
    "        model = get_model(model_name)\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model.to(device)\n",
    "\n",
    "        # Resample if needed\n",
    "        if sr != model.samplerate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, model.samplerate)\n",
    "            wav = resampler(wav)\n",
    "            sr = model.samplerate\n",
    "\n",
    "        wav = wav.to(device)\n",
    "\n",
    "        # Separate\n",
    "        with torch.no_grad():\n",
    "            sources = apply_model(model, wav, device=device)  # (1, nsrc, C, T)\n",
    "\n",
    "        # Save stems\n",
    "        out_dir = Path(output_dir)\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        base = Path(input_file).stem\n",
    "        sources = sources.cpu()\n",
    "\n",
    "        stem_paths: Dict[str, str] = {}\n",
    "        print(f\"\\nSaving stems to: {out_dir}\")\n",
    "        for i, stem_name in enumerate(model.sources):\n",
    "            out_path = out_dir / f\"{base}_{stem_name}.wav\"\n",
    "            # sources[0, i] -> (C, T)\n",
    "            _safe_save_audio(sources[0, i], str(out_path), sr)\n",
    "            stem_paths[stem_name] = str(out_path)\n",
    "\n",
    "        return stem_paths\n",
    "\n",
    "    def use(self, tool_input: str) -> str:\n",
    "        \"\"\"\n",
    "        Run the tool.\n",
    "        Expects a JSON string like:\n",
    "          {\"input_file\":\"dreams.mp3\",\"output_dir\":\"separated_stems\",\"model_name\":\"htdemucs_6s\"}\n",
    "        Returns a human-readable report.\n",
    "        \"\"\"\n",
    "        # Parse inputs\n",
    "        try:\n",
    "            params = json.loads(tool_input) if tool_input.strip() else {}\n",
    "            input_file = params.get(\"input_file\")\n",
    "            output_dir = params.get(\"output_dir\", \"separated_stems\")\n",
    "            model_name = params.get(\"model_name\", \"htdemucs\")\n",
    "        except json.JSONDecodeError:\n",
    "            return (\n",
    "                \"Input parsing error: expected a JSON string, e.g.\\n\"\n",
    "                '{\"input_file\":\"dreams.mp3\",\"output_dir\":\"separated_stems\",\"model_name\":\"htdemucs_6s\"}'\n",
    "            )\n",
    "\n",
    "        # Validate required arg\n",
    "        if not input_file:\n",
    "            return \"Missing required field: 'input_file'\"\n",
    "\n",
    "        # Dependency sanity check\n",
    "        missing = []\n",
    "        for pkg in [\"demucs\", \"librosa\", \"soundfile\", \"torch\", \"torchaudio\"]:\n",
    "            try:\n",
    "                __import__(pkg)\n",
    "            except Exception:\n",
    "                missing.append(pkg)\n",
    "        if missing:\n",
    "            return (\n",
    "                \"Missing required packages: \" + \", \".join(missing) +\n",
    "                \"\\nInstall with: pip install demucs librosa soundfile torch torchaudio\"\n",
    "            )\n",
    "\n",
    "        # Run separation\n",
    "        try:\n",
    "            stem_paths = self._separate_stems(\n",
    "                input_file=input_file,\n",
    "                output_dir=output_dir,\n",
    "                model_name=model_name,\n",
    "            )\n",
    "        except FileNotFoundError as e:\n",
    "            return f\"Error: {e}\"\n",
    "        except Exception as e:\n",
    "            return f\"Separation failed: {type(e).__name__}: {e}\"\n",
    "\n",
    "        # Build report\n",
    "        lines = [\n",
    "            \"Stem Separation Complete âœ…\",\n",
    "            f\"- Input: {input_file}\",\n",
    "            f\"- Model: {model_name}\",\n",
    "            f\"- Output directory: {output_dir}\",\n",
    "            \"\",\n",
    "            \"Saved stems:\"\n",
    "        ]\n",
    "        for name, path in stem_paths.items():\n",
    "            lines.append(f\"  â€¢ {name:10s} -> {path}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "SeparateStemsTool = SeparateStemsTool()\n",
    "\n",
    "print(\"âœ“ Specialized tools created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1cd21",
   "metadata": {},
   "source": [
    "## Giving agent tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45b6c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeparateStemsTool -> <__main__.SeparateStemsTool object at 0x00000237074532C0> | type: <class '__main__.SeparateStemsTool'>\n",
      "isclass? False\n",
      "Deleted shadowed SeparateStemsTool binding.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SeparateStemsTool' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m tool_registry = ToolRegistry()\n\u001b[32m     23\u001b[39m separate_stems_tool = SeparateStemsTool()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mtool_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseparate_stems_tool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m available_tools = [tool.name \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tool_registry.get_all_tools().values()]\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAgent\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms tools: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavailable_tools\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EBliv\\Downloads\\Computer Science\\final-project-aymeric-et-louis\\.venv\\Lib\\site-packages\\fairlib\\modules\\action\\tools\\registry.py:31\u001b[39m, in \u001b[36mToolRegistry.register_tool\u001b[39m\u001b[34m(self, tool)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mregister_tool\u001b[39m(\u001b[38;5;28mself\u001b[39m, tool: AbstractTool):\n\u001b[32m     23\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    Adds a tool instance to the registry, making it available for use.\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \u001b[33;03m        tool: An instance of a class that inherits from AbstractTool.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m:\n\u001b[32m     32\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTool must have a name attribute.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRegistering tool: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'SeparateStemsTool' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# Create a registry to hold all tools\n",
    "tool_registry = ToolRegistry()\n",
    "\n",
    "# Instantiate the tool (lowercase variable so you don't shadow the class)\n",
    "separate_stems_tool = SeparateStemsTool()\n",
    "\n",
    "# Register it so the agent knows it exists\n",
    "tool_registry.register_tool(separate_stems_tool)\n",
    "\n",
    "# See what tools are available\n",
    "available_tools = [tool.name for tool in tool_registry.get_all_tools().values()]\n",
    "print(f\"Agent's tools: {available_tools}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf408d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fairlib.modules.action.tools.abstract'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfairlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabstract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AbstractTool\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSeparateStemsTool\u001b[39;00m(AbstractTool):\n\u001b[32m      4\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Tool for separating music into stems using Demucs\"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'fairlib.modules.action.tools.abstract'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
